{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23ad1562",
   "metadata": {},
   "source": [
    "## Prepare dataset:\n",
    "\n",
    "It processes our dataset like this:\n",
    "\n",
    "1) obtain the held-out set (HOS) which includes 1515 data samples whose positions are {-12.502, -29.5, and -41.9};\n",
    "\n",
    "2) split the rest (model-learning set; MLS) into training set (80% of 5636 data samples) and validation set(20% of 5636 data samples);\n",
    "\n",
    "3) after running, you will get a new folder named **dnn_dataset** which includes:\n",
    "\n",
    "    -hos.csv: the HOS set (1515 data samples)\n",
    "    \n",
    "    -training.csv: the training set (80% of 5636 data samples of MLS)\n",
    "    \n",
    "    -validation.csv: for validation set (20% of 5636 data samples of MLS)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c706ec",
   "metadata": {},
   "source": [
    "First, let's import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc0d0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------improt packages------#\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2611dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- read the extracted csv data into a dataframe\n",
    "df = pd.read_csv('processed_csv/processed_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81f9c926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>y=0.0, num=924\n",
      ">>>y=-3.969, num=500\n",
      ">>>y=-9.988, num=613\n",
      ">>>y=-12.502, num=395\n",
      ">>>y=-17.992, num=357\n",
      ">>>y=-19.7, num=376\n",
      ">>>y=-21.034000000000002, num=747\n",
      ">>>y=-24.076999999999998, num=567\n",
      ">>>y=-29.5, num=634\n",
      ">>>y=-36.116, num=560\n",
      ">>>y=-39.4, num=386\n",
      ">>>y=-41.01, num=606\n",
      ">>>y=-41.9, num=486\n",
      "The total samples we have are 7151\n"
     ]
    }
   ],
   "source": [
    "#----- get the unique positions we have in the dataset\n",
    "y = df['y'].unique()\n",
    "for item in y:\n",
    "    cur_df = df[df['y']==item]\n",
    "    print('>>>y={}, num={}'.format(item, len(cur_df)))\n",
    "print('The total samples we have are {}'.format(len(df)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c80ed7",
   "metadata": {},
   "source": [
    "The function **get_hos_mls** will split the dataset (7151 data samples) into:\n",
    "\n",
    "1) held-out set (1515 data samples);\n",
    "\n",
    "2) model-learning set: training set (80% of 5636 data samples) and validation set (20% of 5636 data samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb460ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ held_out_positions: the positions we want to put into HOS\n",
    "#------ input_file: the extracted csv file\n",
    "#------ hos_file: the file name of HOS \n",
    "#------ training_file: the file name of training set\n",
    "#------ validation_file: the file name of validation set\n",
    "\n",
    "def get_hos_mls(held_out_positions, input_file, hos_file, training_file, validation_file):\n",
    "\n",
    "    org_combined_df = pd.read_csv(input_file)\n",
    "    unique_y = org_combined_df['y'].unique()\n",
    "    \n",
    "    \n",
    "    #-First, divide the whole dataset into Held-out set (HOS) and Model-learning set (MLS)\n",
    "    \n",
    "    hos_df = org_combined_df[org_combined_df['y'].isin(held_out_positions)]\n",
    "    mls_df = pd.concat([org_combined_df,hos_df]).drop_duplicates(keep=False)\n",
    "    \n",
    "    \n",
    "    #-Second, split Model-learning set (MLS) into training set and validation set\n",
    "    #-To ensure the training set and validation have the same distribution, we do stratify splitting.\n",
    "    training_df, validation_df = train_test_split(mls_df, test_size = 0.2, random_state = 42,stratify=mls_df['y'])\n",
    "    \n",
    "    #-Save our dataset\n",
    "    hos_df.to_csv(hos_file, index=False)\n",
    "    training_df.to_csv(training_file, index=False)\n",
    "    validation_df.to_csv(validation_file, index=False)\n",
    "    \n",
    "    print('We have {} data samples in HOS'.format(len(hos_df)))\n",
    "    print('We have {} data samples in Training set'.format(len(training_df)))\n",
    "    print('We have {} data samples in Validation set'.format(len(validation_df)))\n",
    "    print('')\n",
    "    print('')\n",
    "    print('>>> Congrats! Datasets have been saved successfully!')\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6daf891",
   "metadata": {},
   "source": [
    "Below, we start to run our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bfaf983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no need to create it!\n",
      "We have 1515 data samples in HOS\n",
      "We have 4508 data samples in Training set\n",
      "We have 1128 data samples in Validation set\n",
      "\n",
      "\n",
      ">>> Congrats! Datasets have been saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#------ Start to run ------#\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # create folder if not exists\n",
    "    if not os.path.exists('dnn_dataset'):\n",
    "        os.makedirs('dnn_dataset')\n",
    "    else:\n",
    "        print('There is no need to create it!')\n",
    "        \n",
    "    \n",
    "    #-set up parameters\n",
    "    input_file = 'processed_csv/processed_combined.csv'\n",
    "    hos_file = 'dnn_dataset/hos.csv'\n",
    "    training_file = 'dnn_dataset/training.csv'\n",
    "    validation_file = 'dnn_dataset/validation.csv'\n",
    "    held_out_positions = [-12.502, -29.5, -41.9]\n",
    "    \n",
    "    get_hos_mls(held_out_positions, input_file, hos_file, training_file, validation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147ef50f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
