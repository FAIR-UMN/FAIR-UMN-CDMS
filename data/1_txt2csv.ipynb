{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a683804",
   "metadata": {},
   "source": [
    "# Transfer raw txt dataset into csv format\n",
    "\n",
    "This notebook will extract data from raw txt and format it into csv/dataframe.\n",
    "1) raw data is located under **/raw_txt**;\n",
    "\n",
    "2) new csv data will be saved under **/processed_csv**.\n",
    "\n",
    "3) after running, you will get:\n",
    "\n",
    "    - a series of csv files under \"/processed_csv\";\n",
    "    \n",
    "    - a combined csv file named \"/processed_csv/processed_combined.csv\";\n",
    "    \n",
    "    - a readme file named \"/processed_csv/readme.csv\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca8f98",
   "metadata": {},
   "source": [
    "First, let's import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b809ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9598b6",
   "metadata": {},
   "source": [
    "The function **process_line** is used to process each line and only extract the needed info. \n",
    "\n",
    "It will return the needed info as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "496875cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_line(line):\n",
    "    info = []\n",
    "    for item in line:\n",
    "        if len(item) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            info.append(item)\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74edc61",
   "metadata": {},
   "source": [
    "The function **txt2csv** is used to transfer raw txt to csv/dataframe and save it. It will call the function **process_line** to process lines one by one.\n",
    "\n",
    "The parameters are:\n",
    "\n",
    "-*raw_txt_file_name*: the file name of the raw txt data\n",
    "\n",
    "-*extracted_csv_file_name*: the file name of the extracted data, it should be a csv file\n",
    "\n",
    "-*readme_file_name*: the file name of \"Readme\", it includes the stastics about the dataset\n",
    "\n",
    "-*drop_feature_list*: the noisy features we want to drop; it can be empty if no features should be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aadab229",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def txt2csv(raw_txt_file_name, extracted_csv_file_name, readme_file_name, drop_feature_list):\n",
    "    # define variables to save results\n",
    "    csv_readme_dict = {'ID':[], 'FileName':[], 'Num':[]}\n",
    "    csv_combine_list = []\n",
    "    count = 0\n",
    "    csv_num = 0\n",
    "    result_dict = {}\n",
    "    \n",
    "    # opening file\n",
    "    raw_txt_file = open(raw_txt_file_name, 'r')\n",
    "    \n",
    "    # processing lines one by one\n",
    "    for line in raw_txt_file:\n",
    "        count += 1\n",
    "        line = line.strip()\n",
    "        #print(\"Line{}: {}\".format(count, line.strip()))\n",
    "        check_line = line.replace('*','')\n",
    "        \n",
    "        if check_line == '':\n",
    "            #print('Empty line; Skip it!')\n",
    "            continue\n",
    "            \n",
    "        if '==>' in line:\n",
    "            #print('The last line for this particular csv file.')\n",
    "            \n",
    "            #### tranfer dict to csv file\n",
    "            result_df = pd.DataFrame.from_dict(result_dict)\n",
    "            \n",
    "            #------------- here, let's check whether we want to want any noisy features\n",
    "            if len(drop_feature_list)!=0:\n",
    "                print('We need to drop **{}** noisy features!'.format(len(drop_feature_list)))\n",
    "                result_df = (result_df.drop(drop_feature_list, 1))\n",
    "            else:\n",
    "                print('We need to drop **{}** noisy features!'.format(len(drop_feature_list)))\n",
    "            \n",
    "            \n",
    "            #-------------- save current dataframe to csv\n",
    "            cur_save_name = extracted_csv_file_name.replace('.csv','')\n",
    "            cur_save_name = cur_save_name + '_{}.csv'.format(csv_num)\n",
    "            result_df.to_csv(cur_save_name, index=False)\n",
    "            print('Congrats! **{}** has been saved!'.format(cur_save_name))\n",
    "            \n",
    "            ########## let's get statistical info #############\n",
    "            csv_readme_dict['ID'].append(csv_num)\n",
    "            csv_readme_dict['FileName'].append(cur_save_name)\n",
    "            csv_readme_dict['Num'].append(len(result_df))\n",
    "            csv_combine_list.append(result_df)\n",
    "            count = 0\n",
    "            csv_num += 1\n",
    "            result_dict = {}\n",
    "            continue\n",
    "            \n",
    "        line = check_line.split(' ')\n",
    "        info = process_line(line)\n",
    "        if count == 2:\n",
    "            for item in info:\n",
    "                result_dict[item]=[]\n",
    "        else:\n",
    "            keys = list(result_dict.keys())\n",
    "            num = len(info)\n",
    "            for i in range(num):\n",
    "                cur_key = keys[i]\n",
    "                cur_info = info[i]\n",
    "                result_dict[cur_key].append(cur_info)\n",
    "    # closing files\n",
    "    raw_txt_file.close()\n",
    "    \n",
    "    # let's save the combined csv and statistical info\n",
    "    combined_df = pd.concat(csv_combine_list, axis=0)\n",
    "    combined_df.to_csv(extracted_csv_file_name, index=False)\n",
    "    csv_readme_dict['ID'].append(csv_readme_dict['ID'][-1]+1)\n",
    "    csv_readme_dict['FileName'].append('combined.csv')\n",
    "    csv_readme_dict['Num'].append(len(combined_df))\n",
    "    csv_readme_df = pd.DataFrame.from_dict(csv_readme_dict)\n",
    "    csv_readme_df.to_csv(readme_file_name, index=False)\n",
    "    \n",
    "    print('')\n",
    "    print('')\n",
    "    print('>>>The raw txt has been processed successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e05f86",
   "metadata": {},
   "source": [
    "Below, we start to run our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02874e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have the folder. Do not need to create it!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_0.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_1.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_2.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_3.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_4.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_5.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_6.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_7.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_8.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_9.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_10.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_11.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_12.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_13.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_14.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_15.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_16.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_17.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_18.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_19.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_20.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_21.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_22.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_23.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_24.csv** has been saved!\n",
      "We need to drop **6** noisy features!\n",
      "Congrats! **processed_csv/processed_combined_25.csv** has been saved!\n",
      "\n",
      "\n",
      ">>>The raw txt has been processed successfully!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    raw_txt_file_name = 'raw_txt/data_all_v4.txt' # the raw txt data file name\n",
    "    extracted_csv_file_name = 'processed_csv/processed_combined.csv' # the extracted data file name \n",
    "    readme_file_name = 'processed_csv/processed_readme.csv' # the readme file name \n",
    "    \n",
    "    # the noisy features we want to remove\n",
    "    drop_feature_list = ['PAamp', 'PBamp', 'PCamp', 'PDamp', 'PFamp', 'energy']\n",
    "    \n",
    "     # create folder if not exists\n",
    "    if not os.path.exists('processed_csv'):\n",
    "        os.makedirs('processed_csv')\n",
    "        print('The folder has been created!')\n",
    "    else:\n",
    "        print('We have the folder. Do not need to create it!')\n",
    "        \n",
    "    txt2csv(raw_txt_file_name, extracted_csv_file_name, readme_file_name, drop_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70683a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
